[project]
name = "reproduce-transformer-pack"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "evaluate>=0.4.6",
    "flash-attn",
    "loguru>=0.7.3",
    "nltk>=3.9.2",
    "psutil>=7.2.2",
    "pydantic>=2.12.5",
    "seaborn>=0.13.2",
    "tokenizers>=0.22.2",
    "tomli-w>=1.2.0",
    "torch==2.9.1",
    "torchvision==0.24.1",
    "tqdm>=4.67.3",
    "wandb>=0.25.0",
]

[tool.uv.extra-build-dependencies]
flash-attn = ["torch"]

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.uv.sources]
torch = [{ index = "pytorch-cu128" }]
torchvision = [{ index = "pytorch-cu128" }]
flash-attn = { url = "https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.7.16/flash_attn-2.8.3%2Bcu128torch2.9-cp312-cp312-linux_x86_64.whl" }

[dependency-groups]
dev = [
    "setuptools==81.0.0",
    "torch-tb-profiler>=0.4.3",
]
